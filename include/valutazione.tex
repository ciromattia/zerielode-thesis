\chapter{Valutazione}

La realizzazione di uno strumento di conversione quanto più automatico possibile ha portato ad una serie di scelte importanti sul trattamento dei dati in input.

La scelta dell'utilizzo di alcune ontologie in luogo di altre, specialmente non ancora conosciute nel dominio dell'eredità culturale, è allo stesso tempo coraggiosa e rischiosa: la mappatura è stata effettuata nell'ottica di mantenere quanto più possibile il dettaglio delle informazioni contenute e pertanto utilizzando classi specifiche di ontologie finora conosciute solamente in campo biblioteconomico (i.e. la suite \emph{SPAR - Semantic Publishing and Referencing}\footnote{\url{http://sempublishing.sourceforge.net}} e \cite{6}). Il rischio è che tali ontologie non vengano accettate come standard nel campo del cultural heritage, costringendo il progetto \emph{Zeri e LODE} a rivederne l'utilizzo oppure ad accettare una parziale fuoriuscita dallo standard.

In questo senso è fondamentale la cooperazione e il dialogo con altri archivi fotografici e progetti che siano diretti all'apertura in LOD della propria base informativa, così da creare una solida base per l'interoperabilità dei dati.

Durante lo sviluppo è poi stato notato come l'iniziale mappatura teorica fatta a fronte dei tracciati riportati in \ref{tab:fzeri-schedaF} e seguenti abbia subito una sostanziale rilettura e parziale modifica con l'analisi dei dati reali XML (cfr.~\ref{sec:fakerecord}) a causa di strutture parzialmente diverse, campi inutilizzati e valori non coerenti con la classe di destinazione definita in prima battuta (cfr. tab.~\ref{tab:schedaf-to-owl} e figg.~\ref{fig:mapping-v3-1} e seguenti).

L'utilizzo di un approccio procedurale quale lo scripting in \emph{Python} ha permesso uno sviluppo più rapido a fronte della scrittura e successiva applicazione di un foglio di stile; la sua divisione in moduli, classi e funzioni indipendenti permette anche un veloce adattamento nel caso il formato di input dovesse essere modificato, grazie anche all'utilizzo della classe \texttt{etree} che permette un rapido accesso all'albero XML e alla presenza di metodi individuali per il parsing dei singoli paragrafi. In questo modo, dovesse l'input variare, sarà sufficiente modificare a livello minimale la parte di lettura dell'albero XML per ottenere la generazione dello stesso output.

L'utilizzo dell'ottima libreria \texttt{rdflib}\footnote{\url{https://rdflib.readthedocs.org/en/latest/}} è risultato importante anche in virtù dei futuri sviluppi: dalla versione 4.0.1 infatti sono state integrate le classi \texttt{SPARQLStore} e \texttt{SPARQLUpdateStore} assieme al kit di funzionalità per il dialogo con un endpoint \emph{SPARQL}: tali funzionalità risulteranno fondamentali in un eventuale futura creazione diretta del triple store in LOD e implementazione di una forma di sincronizzazione bidirezionale con l'archivio Zeri.

Infine, il progetto presentato è stato relazionato nel paper \emph{Converting the Zeri photo archive in Linked Open Data: formalizing the conceptual model} \cite{29} proposto all'\emph{International Conference on Theory and Practice of Digital Libraries (TPDL 2014)}\footnote{\url{http://www.dl2014.org}} e riconosciuto come contributo significativo nel campo della conservazione dell'eredità culturale (accettato tra i 30 \emph{full paper} a fronte di 107 proposte ricevute).
